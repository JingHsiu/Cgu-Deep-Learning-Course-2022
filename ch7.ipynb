{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Working with Keras: A deep dive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## A spectrum of workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Different ways to build Keras models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The `Sequential` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 09:56:37.391674: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Incrementally building a Sequential model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Calling a model for the first time to build it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[-0.18441491,  0.2026208 , -0.06038097,  0.18697965, -0.2050239 ,\n",
       "          0.11643702,  0.06124762,  0.17225909,  0.04417348, -0.14606231,\n",
       "          0.0543043 , -0.10174821, -0.06249535,  0.01305965,  0.04082814,\n",
       "          0.03550312,  0.07198164, -0.22344416,  0.08636564, -0.22303599,\n",
       "          0.10828969, -0.08874927, -0.18410833, -0.26573962,  0.24087393,\n",
       "         -0.14162786,  0.19605103,  0.12106445,  0.00742507,  0.08483252,\n",
       "         -0.191186  , -0.273917  ,  0.01757759, -0.18422356, -0.15682657,\n",
       "         -0.09490314,  0.2624988 ,  0.29055393,  0.27683574,  0.29350257,\n",
       "         -0.09386018, -0.05258091,  0.21482599,  0.04216832,  0.19170868,\n",
       "         -0.07689455, -0.2920758 ,  0.1026606 ,  0.09120029, -0.02988929,\n",
       "         -0.12787229, -0.10057169, -0.00973216,  0.1836288 , -0.102687  ,\n",
       "         -0.2952847 , -0.28537723,  0.22303963,  0.00395015, -0.25982514,\n",
       "         -0.11271046, -0.06698374, -0.10195734, -0.07519691],\n",
       "        [-0.26306397, -0.04792956, -0.00059345,  0.2126652 ,  0.02374992,\n",
       "          0.24548954,  0.01263377,  0.10302433,  0.19510132, -0.01372045,\n",
       "         -0.22665608, -0.14761262,  0.20528501, -0.1842588 ,  0.08914083,\n",
       "         -0.2806676 , -0.05196661,  0.04813355,  0.2783411 , -0.2636931 ,\n",
       "          0.15619928,  0.2553755 ,  0.27225482, -0.1361792 , -0.04215848,\n",
       "         -0.0350306 , -0.06414412, -0.0760309 , -0.29475415,  0.14103833,\n",
       "          0.24379337, -0.08488531,  0.17839876, -0.22309065, -0.04262573,\n",
       "          0.25243932, -0.0197733 ,  0.05214062,  0.16915777,  0.22075385,\n",
       "         -0.06599915,  0.04911941, -0.27865824,  0.00812083, -0.0783302 ,\n",
       "          0.20615166, -0.22265393,  0.04474118,  0.1411143 ,  0.1365335 ,\n",
       "         -0.29859012,  0.2885356 , -0.08924001,  0.11291394,  0.14771685,\n",
       "          0.02938807, -0.18417297,  0.02006376, -0.16574514,  0.15515631,\n",
       "         -0.07122828, -0.2051703 , -0.19810991, -0.0219312 ],\n",
       "        [ 0.15959805, -0.18100265,  0.19847015, -0.11350149,  0.04543155,\n",
       "          0.18257093, -0.14802594,  0.09759915,  0.25103128,  0.19009975,\n",
       "         -0.04000172,  0.04716378, -0.02626321, -0.16727212,  0.26046365,\n",
       "         -0.00351408, -0.23985928, -0.27378085,  0.10168934, -0.06038982,\n",
       "         -0.20538399, -0.03370523,  0.0398123 , -0.22312725, -0.08676076,\n",
       "          0.24539077,  0.06930768,  0.16052458,  0.05447012,  0.049927  ,\n",
       "          0.03278694, -0.16715924, -0.16245303, -0.14526108, -0.00335526,\n",
       "          0.017712  ,  0.04211617, -0.11977784,  0.1729528 ,  0.1665341 ,\n",
       "          0.1739259 ,  0.2647723 , -0.05805691,  0.18398812, -0.04038686,\n",
       "          0.23099917,  0.01380479,  0.15349138,  0.0175173 , -0.00164336,\n",
       "          0.20971316,  0.056196  ,  0.11946741,  0.26650196,  0.27740735,\n",
       "         -0.03279898, -0.2747334 , -0.0466359 , -0.08296472,  0.23512423,\n",
       "         -0.15264419,  0.05720222,  0.14152747,  0.04506925]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[-0.02559209,  0.20336142,  0.14778039,  0.21745774, -0.15480506,\n",
       "         -0.0065724 , -0.04817103, -0.10066767, -0.0484819 , -0.2036556 ],\n",
       "        [ 0.2174168 ,  0.1182242 , -0.11688447, -0.13516945,  0.00436601,\n",
       "         -0.11564985, -0.19030678, -0.21135938, -0.01041201,  0.175028  ],\n",
       "        [ 0.2650117 ,  0.24697682,  0.14052439, -0.12247446,  0.1173622 ,\n",
       "         -0.03929399,  0.19201493,  0.14425036, -0.07069112,  0.23181829],\n",
       "        [ 0.08303505, -0.02551746, -0.02306333, -0.14097199,  0.25373992,\n",
       "         -0.02088812, -0.12310319, -0.00964621,  0.09405318, -0.17873922],\n",
       "        [-0.19464156, -0.17509079,  0.11285281,  0.14454111,  0.17808768,\n",
       "          0.09495625,  0.11886114, -0.07866496,  0.11566287, -0.13095672],\n",
       "        [-0.06638546, -0.14882356, -0.03753003,  0.14285973,  0.06813517,\n",
       "          0.00611612,  0.18099383,  0.27055445,  0.10217997,  0.07347327],\n",
       "        [-0.15435828,  0.22579315,  0.2519774 ,  0.19990188,  0.13315591,\n",
       "         -0.24676841,  0.13493496,  0.21934184,  0.07182059, -0.10580009],\n",
       "        [ 0.09719393,  0.00191766, -0.27046952,  0.18253353,  0.02905083,\n",
       "          0.09018072, -0.15995975,  0.18020922, -0.04424907, -0.10988314],\n",
       "        [ 0.21900132, -0.048692  ,  0.12161377, -0.07610643,  0.1928455 ,\n",
       "         -0.10511489, -0.18499398, -0.15912934, -0.1263958 , -0.04750361],\n",
       "        [-0.18978986, -0.03576213,  0.1933712 , -0.24569447,  0.15334138,\n",
       "          0.22358999,  0.07134089, -0.04771373, -0.19772053, -0.22335523],\n",
       "        [-0.03448683,  0.02547836,  0.18856257,  0.25479105, -0.11538677,\n",
       "          0.25451502, -0.06594948, -0.25271204, -0.13660815,  0.20262837],\n",
       "        [-0.17940134, -0.24723557,  0.02558663, -0.00481319,  0.22772703,\n",
       "          0.23529008, -0.27542195, -0.09927914,  0.16839442, -0.27490586],\n",
       "        [-0.0433376 ,  0.18037394,  0.2102781 ,  0.1359674 , -0.14859056,\n",
       "         -0.250448  ,  0.13816246, -0.07541178, -0.04927172,  0.12628323],\n",
       "        [ 0.23091468, -0.20188797,  0.22382697, -0.04526599, -0.20188472,\n",
       "          0.02077025, -0.26081935, -0.22610964, -0.25740758, -0.01270178],\n",
       "        [-0.04351024,  0.06361362,  0.23218521,  0.14996785, -0.10979985,\n",
       "         -0.04987389,  0.26671585, -0.22627257,  0.00844023,  0.12048322],\n",
       "        [ 0.0141193 , -0.02266842, -0.23394737, -0.10165112, -0.22328131,\n",
       "         -0.10239518,  0.28462425,  0.06195381, -0.06044579,  0.19360429],\n",
       "        [ 0.16851208,  0.21444005, -0.02987742, -0.08854568, -0.04621175,\n",
       "         -0.07899912,  0.26723823,  0.12842405, -0.04548873, -0.24632415],\n",
       "        [ 0.10186332, -0.06155759,  0.06220967,  0.14801487, -0.04942691,\n",
       "         -0.00411814,  0.05022806,  0.01094058,  0.1359419 , -0.10181561],\n",
       "        [-0.02913609, -0.02576518, -0.11245614, -0.04781997,  0.19223565,\n",
       "          0.23279074, -0.24676414,  0.15397573,  0.08098495,  0.24470195],\n",
       "        [-0.16017224,  0.25745603, -0.05114858,  0.1153017 , -0.11398846,\n",
       "         -0.10177168, -0.07933795,  0.23706457,  0.0602136 , -0.0075807 ],\n",
       "        [ 0.20144084, -0.14796959,  0.26124766, -0.25803542, -0.13353243,\n",
       "          0.02753982,  0.02497375, -0.04028612,  0.24990728,  0.05307418],\n",
       "        [ 0.20479587, -0.17410457,  0.06236216, -0.28358254, -0.18068716,\n",
       "         -0.252355  ,  0.2699181 , -0.06936552,  0.14422014,  0.0719381 ],\n",
       "        [-0.28322315, -0.06268436, -0.1453154 , -0.26621008, -0.12757584,\n",
       "         -0.13741575,  0.01607388, -0.20380291,  0.04678026, -0.0261223 ],\n",
       "        [-0.03023407, -0.0762663 , -0.19220427,  0.25579754,  0.09833479,\n",
       "          0.0677025 ,  0.14175293,  0.17420578,  0.13308811,  0.26688662],\n",
       "        [-0.00772402,  0.1322105 ,  0.03260747,  0.18442866,  0.22733209,\n",
       "         -0.09909597, -0.2399897 , -0.0887076 , -0.2006936 , -0.09317537],\n",
       "        [ 0.05391899, -0.15396996, -0.10914634, -0.21913302, -0.09847642,\n",
       "          0.00914657, -0.20337114,  0.19580728,  0.04591691, -0.27232173],\n",
       "        [ 0.11963677, -0.15594031,  0.00715461, -0.21356529, -0.01991493,\n",
       "          0.15890095, -0.01131859, -0.22490779, -0.14225882, -0.03729418],\n",
       "        [-0.17499277,  0.26954797, -0.07778554,  0.23374   ,  0.0447537 ,\n",
       "          0.24244627,  0.17172348, -0.07526386, -0.07390887,  0.12483862],\n",
       "        [ 0.11142728, -0.27223462,  0.2542542 ,  0.2511504 ,  0.17706975,\n",
       "          0.26172844, -0.17429127,  0.18183422, -0.20672846, -0.274455  ],\n",
       "        [-0.13596809, -0.00423947, -0.17508882,  0.18478265, -0.05736457,\n",
       "          0.09744349, -0.13570258,  0.22733387,  0.25698194, -0.09806277],\n",
       "        [ 0.19763118,  0.2695658 , -0.24958989, -0.21958937, -0.22249502,\n",
       "          0.27536336, -0.08590995, -0.23273942, -0.22765581,  0.24613646],\n",
       "        [-0.14474982,  0.0068602 ,  0.15243018, -0.00039262, -0.13047858,\n",
       "          0.25873676,  0.00051311,  0.04120684, -0.14658634,  0.25231567],\n",
       "        [-0.08476277, -0.27549   , -0.17770562,  0.07479113, -0.15372929,\n",
       "         -0.05426665,  0.14603218,  0.03833479,  0.06445828, -0.15871148],\n",
       "        [-0.16355318, -0.08061196,  0.09725651,  0.19554979,  0.12914544,\n",
       "         -0.24471211, -0.20136291,  0.0162802 , -0.27926862, -0.18714973],\n",
       "        [-0.07238136,  0.0812937 ,  0.14360636, -0.00572482,  0.0670917 ,\n",
       "         -0.00204638, -0.1430737 ,  0.09070089,  0.06044611, -0.00423852],\n",
       "        [-0.10108221, -0.01082647, -0.01927549,  0.20149556,  0.11637822,\n",
       "          0.02218696,  0.2809429 , -0.13476163,  0.08706251,  0.14559606],\n",
       "        [-0.19713512,  0.09332582, -0.16172867, -0.05101945, -0.2263759 ,\n",
       "         -0.16545843, -0.00581476, -0.13355769,  0.08651429, -0.20384379],\n",
       "        [ 0.15396413,  0.1730825 ,  0.24182805,  0.12899113, -0.10096964,\n",
       "          0.08999869, -0.12613334, -0.20164703,  0.03889555, -0.04440889],\n",
       "        [ 0.23535916,  0.21208614,  0.27438602, -0.26480702, -0.06467764,\n",
       "          0.17598116, -0.09535576,  0.00916931,  0.17792326,  0.21516475],\n",
       "        [ 0.07468998,  0.22331432,  0.0829736 , -0.12298885, -0.21132244,\n",
       "         -0.27229843,  0.15294069,  0.01918498, -0.04928306, -0.05894034],\n",
       "        [-0.11460191,  0.04318988, -0.1256888 ,  0.12894687, -0.12620951,\n",
       "         -0.23479435,  0.05226311,  0.21979025,  0.07033667,  0.12407503],\n",
       "        [-0.09650281,  0.07216534,  0.07458442, -0.25628054,  0.01612908,\n",
       "         -0.24771689,  0.24263033, -0.07868493, -0.11786452,  0.04622206],\n",
       "        [ 0.22733483, -0.1369776 ,  0.1801934 , -0.03090921, -0.13701616,\n",
       "         -0.0757435 , -0.1001524 , -0.00053883, -0.27793595, -0.15739328],\n",
       "        [-0.08267334, -0.15171991,  0.16363832,  0.20557421,  0.05855277,\n",
       "          0.13830063, -0.26687512, -0.27293232, -0.15021937, -0.17628877],\n",
       "        [ 0.00611845, -0.00718552,  0.1585958 , -0.09424089, -0.01796067,\n",
       "          0.10837832,  0.0911245 , -0.2515366 , -0.14396563, -0.05751297],\n",
       "        [ 0.23367056,  0.21020684,  0.28367147, -0.20793179,  0.08325481,\n",
       "         -0.1490736 ,  0.1628584 ,  0.19475737, -0.08636948, -0.25340587],\n",
       "        [-0.16376452, -0.24714282, -0.05106412,  0.09871757,  0.13530421,\n",
       "          0.10829753,  0.06423867,  0.21887198,  0.09920216,  0.06063899],\n",
       "        [ 0.18710363,  0.26681116,  0.251855  ,  0.00478956,  0.12327617,\n",
       "         -0.10747199,  0.21801719, -0.27709976, -0.12042984,  0.17728224],\n",
       "        [ 0.10158533,  0.16733712,  0.07163274, -0.03927179,  0.09553301,\n",
       "         -0.1331477 , -0.21329917,  0.01267156,  0.07119358, -0.18242764],\n",
       "        [-0.07059044,  0.22050437,  0.08425006,  0.26255658,  0.0146299 ,\n",
       "         -0.24158067,  0.23301306,  0.04666919, -0.22640203, -0.08341503],\n",
       "        [-0.05487779, -0.20273075,  0.15189114,  0.12127513, -0.27106482,\n",
       "         -0.04484521,  0.21350032, -0.07858635,  0.16847739,  0.10684544],\n",
       "        [ 0.17899692,  0.14718315,  0.23450527, -0.00513294, -0.12468193,\n",
       "          0.15812218,  0.22665045, -0.0002909 ,  0.23345146, -0.21195918],\n",
       "        [-0.15770577, -0.0044468 , -0.11324868, -0.15776245, -0.27046475,\n",
       "          0.05840769,  0.16611078,  0.18225133, -0.06883483, -0.13854271],\n",
       "        [ 0.2274321 , -0.20791727,  0.00772646, -0.23689143,  0.26041713,\n",
       "          0.12404731, -0.16506141, -0.13887042, -0.06088978, -0.2607718 ],\n",
       "        [ 0.01031202, -0.18864274,  0.07153076,  0.18731946, -0.23111673,\n",
       "          0.12675771,  0.02799079, -0.2745799 , -0.15778221, -0.16957855],\n",
       "        [-0.06455368,  0.00872946,  0.1830258 ,  0.1666942 , -0.03710926,\n",
       "          0.05891752,  0.20074919,  0.15912703,  0.01809916,  0.23612979],\n",
       "        [ 0.01078248,  0.13086033,  0.20187974, -0.15282711,  0.17721057,\n",
       "          0.05779973,  0.18952388,  0.09739521, -0.25559482, -0.23689693],\n",
       "        [-0.04708683, -0.13000228,  0.10562325,  0.0667133 , -0.11558005,\n",
       "         -0.2420049 , -0.18520355, -0.12455295,  0.00190076,  0.16446662],\n",
       "        [-0.11520477,  0.0206885 ,  0.11804125, -0.05889438, -0.2663538 ,\n",
       "          0.24500409, -0.11207303,  0.12013209, -0.20312117, -0.24139859],\n",
       "        [ 0.26081786, -0.16232881,  0.10647878, -0.07746401,  0.00255454,\n",
       "         -0.11618461, -0.15897848,  0.12213182,  0.03151199, -0.22521281],\n",
       "        [-0.09292744, -0.10803981, -0.03068912, -0.23471783, -0.26501307,\n",
       "         -0.10128839,  0.16795462,  0.21949902, -0.16147998, -0.11708169],\n",
       "        [-0.02487272, -0.04455268, -0.1937465 , -0.21674196, -0.01684138,\n",
       "          0.18779916, -0.0637701 , -0.10315689, -0.11050712, -0.24679346],\n",
       "        [ 0.04833153, -0.1925691 ,  0.10058635,  0.03544021,  0.09196687,\n",
       "         -0.13851862,  0.02274603, -0.0942373 ,  0.21486509, -0.09276268],\n",
       "        [-0.09591103,  0.06659597,  0.2787325 , -0.26076213,  0.11539757,\n",
       "          0.08949932,  0.01420599,  0.11771354,  0.1227881 ,  0.11386552]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build(input_shape=(None, 3))\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The summary method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Naming models and layers with the `name` argument**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_first_layer (Dense)      (None, 64)                256       \n",
      "                                                                 \n",
      " my_last_layer (Dense)       (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\")\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Specifying the input shape of your model in advance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple Functional model with two `Dense` layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = layers.Dense(64, activation=\"relu\")(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_input (InputLayer)       [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Multi-input, multi-output models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A multi-input, multi-output Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "    num_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Training a multi-input, multi-output model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing lists of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 3s 27ms/step - loss: 38.8022 - priority_loss: 0.3376 - department_loss: 38.4646 - priority_mean_absolute_error: 0.5023 - department_accuracy: 0.2719\n",
      "40/40 [==============================] - 1s 8ms/step - loss: 18.4101 - priority_loss: 0.3399 - department_loss: 18.0702 - priority_mean_absolute_error: 0.5047 - department_accuracy: 0.1187\n",
      "40/40 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit([title_data, text_body_data, tags_data],\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate([title_data, text_body_data, tags_data],\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing dicts of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 3s 27ms/step - loss: 46.4999 - priority_loss: 0.3399 - department_loss: 46.1600 - priority_mean_absolute_error: 0.5047 - department_accuracy: 0.2719\n",
      "40/40 [==============================] - 1s 9ms/step - loss: 60.0050 - priority_loss: 0.3399 - department_loss: 59.6651 - priority_mean_absolute_error: 0.5047 - department_accuracy: 0.0656\n",
      "40/40 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
    "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          {\"priority\": priority_data, \"department\": department_data},\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               {\"priority\": priority_data, \"department\": department_data})\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The power of the Functional API: Access to layer connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Retrieving the inputs or outputs of a layer in a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x7fb3917fbf40>,\n",
       " <keras.engine.input_layer.InputLayer at 0x7fb3917fbdf0>,\n",
       " <keras.engine.input_layer.InputLayer at 0x7fb3917fbd30>,\n",
       " <keras.layers.merging.concatenate.Concatenate at 0x7fb3917f5790>,\n",
       " <keras.layers.core.dense.Dense at 0x7fb3917f5d60>,\n",
       " <keras.layers.core.dense.Dense at 0x7fb3917e3130>,\n",
       " <keras.layers.core.dense.Dense at 0x7fb3917ea7c0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
       " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags')>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a new model by reusing intermediate layer outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = model.layers[4].output\n",
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
    "\n",
    "new_model = keras.Model(\n",
    "    inputs=[title, text_body, tags],\n",
    "    outputs=[priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Subclassing the Model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Rewriting our previous example as a subclassed model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = CustomerTicketModel(num_departments=4)\n",
    "\n",
    "priority, department = model(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 24ms/step - loss: 25.7198 - output_1_loss: 0.3256 - output_2_loss: 25.3942 - output_1_mean_absolute_error: 0.4883 - output_2_accuracy: 0.2367\n",
      "40/40 [==============================] - 1s 9ms/step - loss: 10.7547 - output_1_loss: 0.3305 - output_2_loss: 10.4242 - output_1_mean_absolute_error: 0.4953 - output_2_accuracy: 0.2430\n",
      "40/40 [==============================] - 0s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit({\"title\": title_data,\n",
    "           \"text_body\": text_body_data,\n",
    "           \"tags\": tags_data},\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data,\n",
    "                \"text_body\": text_body_data,\n",
    "                \"tags\": tags_data},\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict({\"title\": title_data,\n",
    "                                                  \"text_body\": text_body_data,\n",
    "                                                  \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Beware: What subclassed models don't support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Mixing and matching different components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a Functional model that includes a subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a subclassed model that includes a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Remember: Use the right tool for the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Using built-in training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The standard workflow: `compile()`, `fit()`, `evaluate()`, `predict()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.2921 - accuracy: 0.9129 - val_loss: 0.1449 - val_accuracy: 0.9599\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1680 - accuracy: 0.9526 - val_loss: 0.1242 - val_accuracy: 0.9663\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1400 - accuracy: 0.9626 - val_loss: 0.1079 - val_accuracy: 0.9720\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0990 - accuracy: 0.9735\n",
      "313/313 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom metric by subclassing the `Metric` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 0.2954 - accuracy: 0.9128 - rmse: 7.1878 - val_loss: 0.1492 - val_accuracy: 0.9568 - val_rmse: 7.3604\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1649 - accuracy: 0.9538 - rmse: 7.3548 - val_loss: 0.1182 - val_accuracy: 0.9673 - val_rmse: 7.4022\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 0.1380 - accuracy: 0.9629 - rmse: 7.3899 - val_loss: 0.1142 - val_accuracy: 0.9702 - val_rmse: 7.4137\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1061 - accuracy: 0.9729 - rmse: 7.4282\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The EarlyStopping and ModelCheckpoint callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Using the `callbacks` argument in the `fit()` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.2947 - accuracy: 0.9126 - val_loss: 0.1504 - val_accuracy: 0.9574\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1663 - accuracy: 0.9537 - val_loss: 0.1236 - val_accuracy: 0.9680\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1417 - accuracy: 0.9626 - val_loss: 0.1058 - val_accuracy: 0.9728\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1280 - accuracy: 0.9675 - val_loss: 0.1089 - val_accuracy: 0.9730\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1170 - accuracy: 0.9700 - val_loss: 0.1141 - val_accuracy: 0.9734\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1109 - accuracy: 0.9729 - val_loss: 0.1065 - val_accuracy: 0.9773\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1077 - accuracy: 0.9741 - val_loss: 0.1147 - val_accuracy: 0.9764\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.1021 - accuracy: 0.9759 - val_loss: 0.1182 - val_accuracy: 0.9763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb3633f0610>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=2,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a custom callback by subclassing the `Callback` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.2917 - accuracy: 0.9131 - val_loss: 0.1533 - val_accuracy: 0.9570\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.1649 - accuracy: 0.9536 - val_loss: 0.1393 - val_accuracy: 0.9639\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1404 - accuracy: 0.9621 - val_loss: 0.1142 - val_accuracy: 0.9710\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1275 - accuracy: 0.9675 - val_loss: 0.1069 - val_accuracy: 0.9741\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1165 - accuracy: 0.9704 - val_loss: 0.1091 - val_accuracy: 0.9740\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1099 - accuracy: 0.9724 - val_loss: 0.1098 - val_accuracy: 0.9766\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1029 - accuracy: 0.9756 - val_loss: 0.1220 - val_accuracy: 0.9774\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.1029 - accuracy: 0.9758 - val_loss: 0.1153 - val_accuracy: 0.9768\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1001 - accuracy: 0.9771 - val_loss: 0.1159 - val_accuracy: 0.9777\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0908 - accuracy: 0.9795 - val_loss: 0.1194 - val_accuracy: 0.9777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb35698eac0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Monitoring and visualization with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 0.2925 - accuracy: 0.9132 - val_loss: 0.1466 - val_accuracy: 0.9585\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1628 - accuracy: 0.9546 - val_loss: 0.1185 - val_accuracy: 0.9673\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1364 - accuracy: 0.9635 - val_loss: 0.1134 - val_accuracy: 0.9720\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1243 - accuracy: 0.9687 - val_loss: 0.1088 - val_accuracy: 0.9721\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1162 - accuracy: 0.9708 - val_loss: 0.1119 - val_accuracy: 0.9753\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1085 - accuracy: 0.9732 - val_loss: 0.1002 - val_accuracy: 0.9773\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 0.1065 - accuracy: 0.9751 - val_loss: 0.1220 - val_accuracy: 0.9743\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1023 - accuracy: 0.9766 - val_loss: 0.1091 - val_accuracy: 0.9789\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0970 - accuracy: 0.9782 - val_loss: 0.1112 - val_accuracy: 0.9786\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0919 - accuracy: 0.9793 - val_loss: 0.1202 - val_accuracy: 0.9787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb35c2cf190>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/Users/hsiu/Documents/DeepLearning_with_Python\",\n",
    ")\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9fe18492285a20c8\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9fe18492285a20c8\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /Users/hsiu/Documents/DeepLearning_with_Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Writing your own training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training versus inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Low-level usage of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 1.00\n"
     ]
    }
   ],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of values: 2.00\n"
     ]
    }
   ],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A complete training and evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the training step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: resetting the metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the loop itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results at the end of epoch 0\n",
      "...sparse_categorical_accuracy: 0.9140\n",
      "...loss: 0.2913\n",
      "Results at the end of epoch 1\n",
      "...sparse_categorical_accuracy: 0.9549\n",
      "...loss: 0.1630\n",
      "Results at the end of epoch 2\n",
      "...sparse_categorical_accuracy: 0.9634\n",
      "...loss: 0.1406\n"
     ]
    }
   ],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step evaluation loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9685\n",
      "...val_loss: 0.1264\n"
     ]
    }
   ],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Make it fast with tf.function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding a `tf.function` decorator to our evaluation-step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9685\n",
      "...val_loss: 0.1264\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging fit() with a custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom training step to use with `fit()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 11s 6ms/step - loss: 0.2925\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1654\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb3431e6f40>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.2959 - sparse_categorical_accuracy: 0.9136\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1643 - sparse_categorical_accuracy: 0.9524\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.1368 - sparse_categorical_accuracy: 0.9637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb35ccbaf70>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter07_working-with-keras.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
